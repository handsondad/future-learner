<!DOCTYPE html>
  <html>
    <head>
      <title>DeepSeek R1 详解</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:///c:\Users\QXZ4FNN\.vscode\extensions\shd101wyy.markdown-preview-enhanced-0.8.15\crossnote\dependencies\katex\katex.min.css">
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><html><head><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body></body></html>
    </head>
    <body for="html-export" >
      <div class="crossnote markdown-preview  "  >
      
<h1 id="deepseek-r1-详解">DeepSeek R1 详解 </h1>
<p>以下是通过 DeepSeek Chat来理解其原理，我们可以基于它自身来学习。</p>
<h2 id="为什么-deepseek-r1-是一项重大创新和重要突破">为什么 DeepSeek R1 是一项重大创新和重要突破？ </h2>
<p>DeepSeek 的 R1 解决了一个重大的 AI 挑战：教会模型在不依赖大量标记推理示例数据集的情况下，进行逐步推理。在 R1-Zero 实验中展示的结果表明，仅靠强化学习就可以发展出高级推理能力，从而避免了对大规模监督训练的需求。</p>
<p>R1-Zero 学会了生成详细的推理步骤，自我检查解决方案，并在更困难的问题上花费更多的计算时间。值得注意的是，这些行为并未被明确编程，而是在训练过程中自然涌现的。这表明，通过精心设计，强化学习可以创建出能够有效推理并灵活适应的模型。</p>
<p>一个关键的突破在于奖励系统的设计。DeepSeek 采用了更简单的基于规则的方法，而不是容易发生“奖励欺骗”的复杂多网络系统。模型因生成正确答案（自动验证）以及产生清晰、结构化的推理而获得奖励。这种方法不仅确保了问题的准确解决，还保证了思维链条的一致性和可读性。</p>
<p>为了验证由大型语言模型（LLM）生成的解决方案，DeepSeek 避免了不可靠的方法，例如人工验证或使用另一个 LLM，这些方法可能会引入错误或幻觉。相反，系统要求 LLM 解决编码、数学或逻辑问题，并将结果与预期输出进行比较。在代码生成的情况下，代码会被执行，并将其输出与真实结果进行对比。这种直接的方法确保了大规模的训练示例和可靠的评估。</p>
<h2 id="deepseek-r1-架构设计">DeepSeek R1 架构设计 </h2>
<p align="center">
  <img width="100%" src="file:///c:\Xiuqin\Code\DeepSeek\DeepSeek-R1-main\figures\DeepSeek R1 Architecture.png">
</p>
<p>参考下Open R1的复刻架构图：</p>
<p align="center">
  <img width="100%" src="file:///c:\Xiuqin\Code\DeepSeek\open-r1-main\assets\plan-of-attack.png">
</p>
<h3 id="deepseek-r1-的多阶段训练过程">DeepSeek R1 的多阶段训练过程 </h3>
<p>在 R1-Zero 的成果基础上，DeepSeek R1 实施了一种新颖的四阶段训练流程，旨在保持强大的推理能力的同时，解决纯强化学习的局限性。研究人员在纯强化学习中发现的具体局限性包括：</p>
<h4 id="可读性差"><strong>可读性差</strong> </h4>
<p>尽管 R1-Zero 的输出在逻辑上是正确的，但其结果往往难以理解。这体现在以下几个方面：</p>
<ul>
<li><strong>解释内容零碎或不清晰</strong>：推理步骤的表达不够连贯，难以追踪逻辑链条。</li>
<li><strong>格式和结构不一致</strong>：响应的格式和结构缺乏统一性，增加了阅读难度。</li>
<li><strong>推理链条难以跟随</strong>：推理过程的逻辑链条不够清晰，使得用户难以理解模型的思考路径。</li>
</ul>
<h4 id="语言混杂"><strong>语言混杂</strong> </h4>
<p>R1-Zero 经常出现以下问题：</p>
<ul>
<li><strong>在单次响应中切换语言</strong>：特别是在英语和中文之间频繁切换。</li>
<li><strong>在单一语言查询中混合使用多种语言</strong>：即使查询只用一种语言，模型的响应仍可能混杂多种语言。</li>
<li><strong>推理过程不同部分使用不一致的语言</strong>：不同推理步骤可能使用不同的语言，进一步降低了输出的可读性。</li>
</ul>
<p>有趣的是，研究人员在开发 DeepSeek R1 时发现，强制模型使用单一语言反而会略微降低 R1-Zero 的表现。这表明，模型发现使用多种语言进行推理更有效，尽管这让输出对用户不太友好。</p>
<h4 id="r1-的开发动机">R1 的开发动机 </h4>
<p>正是由于这些局限性，DeepSeek 开发了完整的 R1 模型，并引入了多阶段训练流程，特别是在冷启动数据（cold-start data）和额外的语言一致性奖励方面的改进，以解决上述问题，同时保持强大的推理能力。</p>
<h4 id="总结">总结 </h4>
<p>DeepSeek R1 的多阶段训练流程通过精心设计的冷启动数据、语言一致性奖励和逐步增强的推理能力训练，不仅解决了 R1-Zero 的可读性和语言混杂问题，还进一步提升了模型的推理性能和适应性。这一创新方法为 AI 模型的训练和优化提供了新的思路，标志着在智能系统开发领域的重要进展。</p>
<h3 id="deepseek-r1-训练过程详解"><strong>DeepSeek R1 训练过程详解</strong> </h3>
<p>DeepSeek R1 的训练过程分为四个不同的阶段，每个阶段旨在逐步提升模型的能力。这些阶段相互衔接，从冷启动阶段开始，到最终的通用偏好优化强化学习阶段结束。以下是每个阶段的详细说明：</p>
<h4 id="第一阶段冷启动阶段"><strong>第一阶段：冷启动阶段</strong> </h4>
<p><strong>目标</strong>：通过使用高质量推理小数据集对基础模型进行微调，为强化学习（RL）训练建立一个稳定的起点。</p>
<p><strong>方法</strong>：</p>
<ol>
<li>研究人员通过多种方法收集了一个小规模的长链思维（CoT）示例数据集：
<ul>
<li>使用长链思维作为示例进行少样本提示（few-shot prompting）。</li>
<li>直接提示（未指定）模型生成包含反思和验证的详细答案。</li>
<li>收集 DeepSeek-R1-Zero 的可读格式输出，并由人工标注者进行后处理优化。</li>
</ul>
</li>
<li>收集了数千个此类示例，并用于对 <strong>DeepSeek-V3-Base</strong> 模型进行监督微调（SFT）。</li>
<li>生成的模型作为后续阶段的初始 RL 行为者，避免了从基础模型直接进行 RL 训练的不稳定性。</li>
</ol>
<h4 id="第二阶段推理导向的强化学习"><strong>第二阶段：推理导向的强化学习</strong> </h4>
<p><strong>目标</strong>：通过强化学习（RL）提升模型的推理能力，重点关注数学问题解决、编程挑战和逻辑推理任务。</p>
<p><strong>方法</strong>：</p>
<ol>
<li>在 R1-Zero 使用的 <strong>GRPO 框架</strong> 基础上，引入了额外的 <strong>语言一致性</strong> 奖励组件，以解决 R1-Zero 中观察到的语言混合问题。</li>
<li>该阶段的所有训练示例均可自动生成并验证其正确性：
<ul>
<li><strong>数学</strong>：通过比较结果与预期答案进行验证。</li>
<li><strong>代码</strong>：通过执行代码并比较输出与预期输出（例如通过单元测试）进行验证。</li>
</ul>
</li>
<li>训练模型生成准确且语言一致的推理任务解决方案。</li>
</ol>
<h4 id="第三阶段多领域微调"><strong>第三阶段：多领域微调</strong> </h4>
<p><strong>目标</strong>：将模型的能力从推理任务扩展到通用文本生成任务，如写作、角色扮演和事实问答。</p>
<p><strong>方法</strong>：</p>
<ol>
<li><strong>推理数据</strong>：
<ul>
<li>研究人员整理了推理提示，并通过从第二阶段训练的模型中进行拒绝采样生成了推理轨迹。</li>
<li>使用 <strong>DeepSeek-V3</strong> 判断输出质量。</li>
<li>为提高可读性，过滤掉混合语言、长段落和代码块的输出。</li>
<li>对每个提示进行多次采样，仅保留正确的响应。</li>
<li><strong>结果</strong>：收集了约 <strong>60 万条推理相关的训练示例</strong>。</li>
</ul>
</li>
<li><strong>非推理数据</strong>：
<ul>
<li>对于写作、事实问答和翻译等任务，研究人员重用了 <strong>DeepSeek-V3 SFT 数据集</strong> 的部分内容。</li>
<li>对于某些任务，使用 DeepSeek-V3 生成链式思维（CoT）后再回答问题。较简单的查询（如“你好”）不需要 CoT。</li>
<li><strong>结果</strong>：收集了约 <strong>20 万条非推理训练示例</strong>。</li>
</ul>
</li>
<li>使用包含约 <strong>80 万条示例</strong>（推理 + 非推理）的最终整理数据集对模型进行两轮微调。</li>
<li><strong>训练方法</strong>：采用监督微调（SFT）而非继续强化学习。</li>
</ol>
<h4 id="第四阶段通用偏好优化"><strong>第四阶段：通用偏好优化</strong> </h4>
<p><strong>目标</strong>：通过优化人类在通用场景中的偏好，进一步优化模型的输出质量。</p>
<p><strong>方法</strong>：</p>
<ol>
<li>引入了 <strong>通用偏好优化强化学习</strong>，如训练过程开头所述。</li>
<li>训练模型生成的解决方案不仅要准确解决问题，还要在可读性、清晰度和用户友好性方面符合人类偏好。</li>
<li>此阶段结合了 <strong>机器生成的可验证问题-解决方案对</strong> 和 <strong>人工标注的解决方案偏好</strong>，以指导模型生成更高质量的输出。</li>
</ol>
<h4 id="总结-1"><strong>总结</strong> </h4>
<ul>
<li><strong>第一阶段</strong>：使用小规模推理示例数据集进行冷启动，以稳定 RL 训练过程。</li>
<li><strong>第二阶段</strong>：以推理为导向的 RL，结合自动验证和语言一致性奖励。</li>
<li><strong>第三阶段</strong>：多领域微调，将模型能力扩展到通用文本生成任务。</li>
<li><strong>第四阶段</strong>：通用偏好优化，根据人类偏好优化输出质量。</li>
</ul>
<h2 id="deepseek-r1-zero-和-r1"><strong>DeepSeek R1-Zero 和 R1</strong> </h2>
<p>DeepSeek 开发的 R1-Zero 和 R1 重新思考了如何训练大型语言模型以实现高级推理能力。他们的方法质疑了广泛监督微调是必要的主流观点。相反，他们证明了纯强化学习在自动生成的训练样本上（将成本降为零）应用时，如果结构合理，可以产生令人印象深刻的推理能力。</p>
<h3 id="r1-zero纯强化学习"><strong>R1-Zero：纯强化学习</strong> </h3>
<p>R1-Zero 表明，复杂的推理能力（或思维链能力）可以在大型语言模型（LLM）中通过纯强化学习自然涌现，而无需传统的监督微调阶段。该模型基于 DeepSeek-V3-Base 架构，拥有 6710 亿参数，代表了与传统训练方法的显著不同。</p>
<h3 id="架构细节"><strong>架构细节</strong> </h3>
<p>R1-Zero 的基础架构由 <strong>61 个 Transformer 解码器模块</strong>组成（你可以在我的新书中了解所有关于解码器 Transformer 的内容），采用了混合注意力机制。前三个解码器模块使用密集注意力（词汇量为 13 万 token，嵌入维度为 7168），为基本模式识别和上下文理解奠定了基础。</p>
<p>其余解码器模块采用<strong>混合专家（MoE）架构</strong>，可以更高效（成本更低、速度更快）地处理输入 token。<br>
MoE 架构是一种模型扩展方法，它使用多个专门的神经网络或专家（在 R1 中，每个模块有 256 个专家）以及一个学习到的路由机制（通常是门控网络），动态地将不同输入分配给最合适的专家。与将所有 token 通过整个网络处理不同，MoE 模型为每个 token 选择性激活一部分专家（在 R1 中是 8 个），路由器根据输入的特性决定启用哪些专家。如果你不熟悉 MoE 的内部工作原理，可以阅读这篇文章，然后继续了解 R1-Zero 的训练过程。</p>
<h3 id="训练过程"><strong>训练过程</strong> </h3>
<p>训练从 DeepSeek-V3-Base 模型开始，该模型已经通过 14.8 万亿 token 的预训练，能够在给定上下文中预测下一个 token。</p>
<p><strong>Group Relative Policy Optimization（GRPO）</strong> 是 DeepSeek 在语言模型强化学习中的一项创新。我们来看看它的工作原理以及它与传统方法的区别。</p>
<h3 id="使用-ppo-的-rlhf"><strong>使用 PPO 的 RLHF</strong> </h3>
<p>传统的 RLHF（基于人类反馈的强化学习）依赖于**近端策略优化（PPO）**算法。PPO 在 RLHF 中是一种利用奖励信号训练语言模型以生成更好输出的方法。如果你不熟悉这一主题，可以阅读这篇文章，然后继续了解 GRPO。简而言之，使用 PPO 的 RLHF 过程如下：</p>
<p><strong>关键组件：</strong></p>
<ul>
<li><strong>策略模型（Actor）</strong>：正在训练的生成文本的语言模型</li>
<li><strong>参考模型</strong>：通常是初始的监督微调（SFT）模型，保持“冻结”状态</li>
<li><strong>奖励模型</strong>：根据人类偏好训练，用于对输出进行评分</li>
<li><strong>价值模型（Critic）</strong>：预测未来预期奖励以进行优势估计</li>
</ul>
<p><strong>过程：</strong></p>
<ol>
<li>策略模型为给定提示生成文本输出</li>
<li>奖励模型对这些输出进行评分</li>
<li>价值模型估计每个 token 位置的预期奖励</li>
<li>PPO 计算优势——每个动作（预测的 token）比预期好或差多少</li>
<li>更新策略模型，以增加导致高于预期奖励的动作的概率</li>
<li>参考模型的 KL 惩罚（Kullback-Leibler 散度）防止策略变化过大</li>
</ol>
<p>RLHF 中最具挑战性的部分是，奖励只在最后（当完整文本被评估时）出现，但模型需要为其生成的每个 token 提供反馈。价值模型通过学习预测未来奖励，帮助系统将所有导致良好结果的决策的功劳分配。</p>
<p>训练循环交替进行：</p>
<ol>
<li>收集生成的批次及其奖励</li>
<li>使用 PPO 目标更新策略</li>
<li>定期更新价值模型以更好预测奖励</li>
</ol>
<p>所有这些共同作用，逐渐引导模型生成获得更高奖励的输出，同时保持连贯和高质量的文本生成。这是一个复杂的优化过程，需要仔细调整多个组件和超参数以有效运行。</p>
<h3 id="使用-grpo"><strong>使用 GRPO</strong> </h3>
<p>GRPO 是 PPO 的一种变体，它在保持有效强化学习的同时，消除了对价值模型的需求。GRPO 采用了与 PPO 不同的方法：它不使用价值模型来估计优势计算中的基线，而是为每个输入生成多个输出，并使用每组输出的平均奖励作为基线。这意味着，如果你为一个数学问题生成了 64 个输出，其中一个解决方案的奖励为 0.9，而组平均值为 0.7，那么该解决方案将获得 0.2 的正向优势。这种基于组的方法提供了一种自然的方式来判断输出是好于还是差于平均水平，而无需单独的价值模型进行预测。虽然 RLHF/PPO 和 GRPO 都旨在通过奖励信号改进模型，但 GRPO 通过利用组统计而不是训练额外的价值模型，更高效地实现了这一目标。这也使 GRPO 与 DPO 不同，因为 DPO 侧重于直接优化成对输出之间的偏好概率，而不是使用任何形式的优势估计。</p>
<p align="center">
  <img width="100%" src="file:///c:\Xiuqin\Code\DeepSeek\DeepSeek-R1-main\figures\PPO-GRPO.png">
</p>
<p>GRPO 最显著的特点之一是自我验证行为的出现。随着训练的进行，模型自然地发展出捕捉和纠正自身错误的能力。这体现在研究人员所称的“顿悟时刻”——模型明确识别推理中的错误并修正其方法的实例。例如，在解决复杂的数学问题时，模型可能会写“等等，我注意到前一步有错误...”，然后继续纠正其计算。这种行为并非明确编程，而是作为基于组的奖励结构的结果而出现。</p>
<p><strong>奖励结构设计</strong><br>
DeepSeek 训练过程中的奖励结构由多个部分组成，这些部分共同协作以指导模型学习，而不需要人类反馈。其核心系统使用两种主要类型的奖励：准确性奖励和格式奖励：</p>
<p>“准确性奖励模型评估响应是否正确。例如，在有确定性结果的数学问题中，模型需要以指定格式（如在一个方框内）提供最终答案，从而实现基于规则的可靠正确性验证。同样，对于 LeetCode 问题，可以使用编译器根据预定义的测试用例生成反馈。”</p>
<p>“除了准确性奖励模型，我们还采用了一个格式奖励模型，要求模型将其思考过程放在 <code>&lt;think&gt;</code> 和 <code>&lt;/think&gt;</code> 标签之间。”</p>
<p>这种奖励结构的一个特别创新的方面是，它能够在没有任何人类反馈的情况下推动改进。该系统完全依赖于程序化验证和结构分析，使其具有高度可扩展性。这种方法使训练过程能够快速评估数百万个响应，从而实现快速迭代和改进。没有人类反馈也消除了人类评估者可能引入的潜在偏见，并允许模型发现人类可能不会考虑的新颖解决问题的方法。</p>
<h2 id="关于-kl-散度">关于 KL 散度 </h2>
<p>KL散度（Kullback-Leibler divergence），也被称为相对熵（relative entropy），是信息论中用于度量两个概率分布差异的一种方式。它衡量的是一个概率分布相对于另一个概率分布的“信息增益”或者“信息损失”。</p>
<h3 id="定义">定义 </h3>
<p>设 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span> 是两个定义在同一随机变量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> 上的概率分布，KL 散度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mtext>KL</mtext></msub><mo stretchy="false">(</mo><mi>P</mi><mo>∥</mo><mi>Q</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">D_{\text{KL}}(P \parallel Q)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">KL</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mclose">)</span></span></span></span> 的定义为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>D</mi><mtext>KL</mtext></msub><mo stretchy="false">(</mo><mi>P</mi><mo>∥</mo><mi>Q</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>X</mi></mrow></munder><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">D_{\text{KL}}(P \parallel Q) = \sum_{x \in X} P(x) \log\left(\frac{P(x)}{Q(x)}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">KL</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.7717em;vertical-align:-1.3217em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8557em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3217em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span></span></span></p>
<p>如果 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span> 是连续概率分布，则 KL 散度定义为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>D</mi><mtext>KL</mtext></msub><mo stretchy="false">(</mo><mi>P</mi><mo>∥</mo><mi>Q</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∫</mo><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mi mathvariant="normal">∞</mi></msubsup><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo fence="true">)</mo></mrow><mi>d</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">D_{\text{KL}}(P \parallel Q) = \int_{-\infty}^{\infty} P(x) \log\left(\frac{P(x)}{Q(x)}\right) dx</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">KL</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4203em;vertical-align:-0.9703em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4143em;"><span style="top:-1.7881em;margin-left:-0.4445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">∞</span></span></span></span><span style="top:-3.8129em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∞</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9703em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span></span></span></span></span></p>
<p>这里，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\log</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span></span></span></span> 通常采用自然对数（ln），但也可以根据应用场合选择其他对数底数。</p>
<h3 id="特点">特点 </h3>
<ul>
<li><strong>非对称性</strong>：KL散度不是距离度量，因为它是非对称的，即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mtext>KL</mtext></msub><mo stretchy="false">(</mo><mi>P</mi><mo>∥</mo><mi>Q</mi><mo stretchy="false">)</mo><mo mathvariant="normal">≠</mo><msub><mi>D</mi><mtext>KL</mtext></msub><mo stretchy="false">(</mo><mi>Q</mi><mo>∥</mo><mi>P</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">D_{\text{KL}}(P \parallel Q) \neq D_{\text{KL}}(Q \parallel P)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">KL</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="inner"><span class="mord"><span class="mrel"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">KL</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span></span></span></span>，也就是说，从 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> 到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span> 的散度和从 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span> 到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> 的散度通常是不同的。</li>
<li><strong>非负性</strong>：KL散度总是非负的，即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mtext>KL</mtext></msub><mo stretchy="false">(</mo><mi>P</mi><mo>∥</mo><mi>Q</mi><mo stretchy="false">)</mo><mo>≥</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">D_{\text{KL}}(P \parallel Q) \geq 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">KL</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span>。</li>
<li><strong>唯一最小值</strong>：仅当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>=</mo><mi>Q</mi></mrow><annotation encoding="application/x-tex">P = Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span> 时，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mtext>KL</mtext></msub><mo stretchy="false">(</mo><mi>P</mi><mo>∥</mo><mi>Q</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">D_{\text{KL}}(P \parallel Q) = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">KL</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span>。这意味着两个相等的分布之间的 KL 散度为零，是唯一可以使 KL 散度为零的情况。</li>
</ul>
<h3 id="实际应用">实际应用 </h3>
<ul>
<li><strong>模型拟合</strong>：在机器学习中，KL 散度经常用于衡量预测的概率分布和真实概率分布之间的差异，特别在最大似然估计和生成对抗网络（GANs）中。</li>
<li><strong>信息增益</strong>：当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> 代表实际或目标分布，而 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span> 代表模型估计分布时，KL 散度可以提供关于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span> 对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> 的信息增益的指标。</li>
<li><strong>编码理论</strong>：在编码理论中，KL 散度可以解释为使用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span> 编码 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> 的“多余信息”。</li>
</ul>
<h3 id="注意事项">注意事项 </h3>
<p>使用 KL 散度时，必须确保 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span> 在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">P(x) &gt; 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span> 的所有点上都是正的，因为如果 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">Q(x) = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span> 而 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">P(x) &gt; 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span>，则 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\log\left(\frac{P(x)}{Q(x)}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span></span></span></span> 为无穷大，导致 KL 散度定义不明确。在实际中，通常采用小的正数（如 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\epsilon &gt; 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">ϵ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span>）平滑 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span> 来避免这种情况。</p>
<h2 id="关于交叉熵损失">关于交叉熵损失 </h2>
<p>交叉熵损失（Cross-Entropy Loss）是一种常用的损失函数，特别是在分类问题中，比如深度学习中的图像分类、自然语言处理中的文本分类等任务。它衡量的是模型预测概率分布与实际概率分布之间的差异，越相似则损失越小，越不相似则损失越大。</p>
<h3 id="理解交叉熵损失">理解交叉熵损失 </h3>
<p>假设我们有一个分类问题，总共有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> 个类别，对于每一个样本，模型会输出对每一个类别的预测概率，我们记为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\hat{y}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 个类别的预测概率。实际上只有一个类别的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\hat{y}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 应该接近1，其余接近0。</p>
<p>实际标签通常以 one-hot 编码的形式给出，记为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">y_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。例如，如果一个样本实际上是类别 2，在一个三分类问题中，其 one-hot 编码就是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0, 1, 0]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">0</span><span class="mclose">]</span></span></span></span>。</p>
<h3 id="交叉熵损失公式">交叉熵损失公式 </h3>
<p>对于单个样本的交叉熵损失定义为：<br>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="script">L</mi><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msub><mi>y</mi><mi>i</mi></msub><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{L} = -\sum_{i=1}^{K} y_i \log(\hat{y}_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal">L</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\log</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span></span></span></span> 表示自然对数，这种损失函数会将正确分类的对数概率放大（因为概率的对数），而惩罚那些分类错误的概率（因为对数会将0~1区间内的数映射到负无穷到0之间，越接近0的预测概率，损失就会越大）。</p>
<h3 id="平均交叉熵损失">平均交叉熵损失 </h3>
<p>在训练神经网络时，我们通常计算的是一个批次内所有样本的平均交叉熵损失，即：<br>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="script">L</mi><mtext>avg</mtext></msub><mo>=</mo><mo>−</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msubsup><mi>y</mi><mi>i</mi><mrow><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msubsup><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msubsup><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi><mrow><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}_{\text{avg}} = -\frac{1}{N}\sum_{n=1}^{N}\sum_{i=1}^{K} y_i^{(n)} \log(\hat{y}_i^{(n)})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">avg</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2769em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2769em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 是批次大小，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>y</mi><mi>i</mi><mrow><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">y_i^{(n)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3217em;vertical-align:-0.2769em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2769em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi><mrow><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\hat{y}_i^{(n)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3217em;vertical-align:-0.2769em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4231em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2769em;"><span></span></span></span></span></span></span></span></span></span> 分别表示第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> 个样本的实际标签和模型预测概率。</p>
<h3 id="交叉熵损失的优势">交叉熵损失的优势 </h3>
<ol>
<li><strong>目标清晰</strong>：交叉熵损失目标明确，对模型的优化直接作用于分类准确率的提高。</li>
<li><strong>数值稳定性</strong>：通过对概率应用对数，可以有效避免数值上乘法可能引起的下溢问题。</li>
<li><strong>梯度引导</strong>：损失函数的导数对模型参数的梯度更新有明确的指导作用，使学习过程高效收敛。</li>
</ol>
<h3 id="实现和使用">实现和使用 </h3>
<p>在深度学习框架中，例如 PyTorch 和 TensorFlow，都有内建的交叉熵损失函数，可以方便地在模型训练过程中使用。例如，在 PyTorch 中，可以使用 <code>nn.CrossEntropyLoss()</code>，并且通常和 softmax 函数结合使用，因为交叉熵损失函数实际上已经包含了 softmax 层的效果（即 log_softmax + NLLLoss）。这使得我们可以直接将模型的原始输出（logits）传递给损失函数。</p>
<h2 id="代码详解">代码详解 </h2>
<p>参考的是HuggingFace的open-r1代码</p>
<pre data-role="codeBlock" data-info="python" class="language-python python"><code>    <span class="token comment"># Load the dataset</span>
    dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span>script_args<span class="token punctuation">.</span>dataset_name<span class="token punctuation">,</span> name<span class="token operator">=</span>script_args<span class="token punctuation">.</span>dataset_config<span class="token punctuation">)</span>

    <span class="token comment"># Get reward functions</span>
    REWARD_FUNCS_REGISTRY <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token string">"accuracy"</span><span class="token punctuation">:</span> accuracy_reward<span class="token punctuation">,</span>
        <span class="token string">"format"</span><span class="token punctuation">:</span> format_reward<span class="token punctuation">,</span>
        <span class="token string">"reasoning_steps"</span><span class="token punctuation">:</span> reasoning_steps_reward<span class="token punctuation">,</span>
        <span class="token string">"cosine"</span><span class="token punctuation">:</span> get_cosine_scaled_reward<span class="token punctuation">(</span>
            min_value_wrong<span class="token operator">=</span>script_args<span class="token punctuation">.</span>cosine_min_value_wrong<span class="token punctuation">,</span>
            max_value_wrong<span class="token operator">=</span>script_args<span class="token punctuation">.</span>cosine_max_value_wrong<span class="token punctuation">,</span>
            min_value_correct<span class="token operator">=</span>script_args<span class="token punctuation">.</span>cosine_min_value_correct<span class="token punctuation">,</span>
            max_value_correct<span class="token operator">=</span>script_args<span class="token punctuation">.</span>cosine_max_value_correct<span class="token punctuation">,</span>
            max_len<span class="token operator">=</span>script_args<span class="token punctuation">.</span>cosine_max_len<span class="token punctuation">,</span>
        <span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"repetition_penalty"</span><span class="token punctuation">:</span> get_repetition_penalty_reward<span class="token punctuation">(</span>
            ngram_size<span class="token operator">=</span>script_args<span class="token punctuation">.</span>repetition_n_grams<span class="token punctuation">,</span>
            max_penalty<span class="token operator">=</span>script_args<span class="token punctuation">.</span>repetition_max_penalty<span class="token punctuation">,</span>
        <span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span>
    reward_funcs <span class="token operator">=</span> <span class="token punctuation">[</span>REWARD_FUNCS_REGISTRY<span class="token punctuation">[</span>func<span class="token punctuation">]</span> <span class="token keyword keyword-for">for</span> func <span class="token keyword keyword-in">in</span> script_args<span class="token punctuation">.</span>reward_funcs<span class="token punctuation">]</span>

    <span class="token comment"># Format into conversation</span>
    <span class="token keyword keyword-def">def</span> <span class="token function">make_conversation</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword keyword-return">return</span> <span class="token punctuation">{</span>
            <span class="token string">"prompt"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
                <span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> SYSTEM_PROMPT<span class="token punctuation">}</span><span class="token punctuation">,</span>
                <span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> example<span class="token punctuation">[</span><span class="token string">"problem"</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span>

    dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>make_conversation<span class="token punctuation">)</span>
    <span class="token keyword keyword-for">for</span> split <span class="token keyword keyword-in">in</span> dataset<span class="token punctuation">:</span>
        <span class="token keyword keyword-if">if</span> <span class="token string">"messages"</span> <span class="token keyword keyword-in">in</span> dataset<span class="token punctuation">[</span>split<span class="token punctuation">]</span><span class="token punctuation">.</span>column_names<span class="token punctuation">:</span>
            dataset<span class="token punctuation">[</span>split<span class="token punctuation">]</span> <span class="token operator">=</span> dataset<span class="token punctuation">[</span>split<span class="token punctuation">]</span><span class="token punctuation">.</span>remove_columns<span class="token punctuation">(</span><span class="token string">"messages"</span><span class="token punctuation">)</span>

    logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"*** Initializing model kwargs ***"</span><span class="token punctuation">)</span>
    torch_dtype <span class="token operator">=</span> <span class="token punctuation">(</span>
        model_args<span class="token punctuation">.</span>torch_dtype <span class="token keyword keyword-if">if</span> model_args<span class="token punctuation">.</span>torch_dtype <span class="token keyword keyword-in">in</span> <span class="token punctuation">[</span><span class="token string">"auto"</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token keyword keyword-else">else</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>torch<span class="token punctuation">,</span> model_args<span class="token punctuation">.</span>torch_dtype<span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    model_kwargs <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>
        revision<span class="token operator">=</span>model_args<span class="token punctuation">.</span>model_revision<span class="token punctuation">,</span>
        trust_remote_code<span class="token operator">=</span>model_args<span class="token punctuation">.</span>trust_remote_code<span class="token punctuation">,</span>
        attn_implementation<span class="token operator">=</span>model_args<span class="token punctuation">.</span>attn_implementation<span class="token punctuation">,</span>
        torch_dtype<span class="token operator">=</span>torch_dtype<span class="token punctuation">,</span>
        use_cache<span class="token operator">=</span><span class="token boolean">False</span> <span class="token keyword keyword-if">if</span> training_args<span class="token punctuation">.</span>gradient_checkpointing <span class="token keyword keyword-else">else</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    training_args<span class="token punctuation">.</span>model_init_kwargs <span class="token operator">=</span> model_kwargs

    <span class="token comment">#############################</span>
    <span class="token comment"># Initialize the GRPO trainer</span>
    <span class="token comment">#############################</span>
    trainer <span class="token operator">=</span> GRPOTrainer<span class="token punctuation">(</span>
        model<span class="token operator">=</span>model_args<span class="token punctuation">.</span>model_name_or_path<span class="token punctuation">,</span>
        reward_funcs<span class="token operator">=</span>reward_funcs<span class="token punctuation">,</span>  <span class="token comment"># 传递奖励函数</span>
        args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
        train_dataset<span class="token operator">=</span>dataset<span class="token punctuation">[</span>script_args<span class="token punctuation">.</span>dataset_train_split<span class="token punctuation">]</span><span class="token punctuation">,</span>
        eval_dataset<span class="token operator">=</span>dataset<span class="token punctuation">[</span>script_args<span class="token punctuation">.</span>dataset_test_split<span class="token punctuation">]</span> <span class="token keyword keyword-if">if</span> training_args<span class="token punctuation">.</span>eval_strategy <span class="token operator">!=</span> <span class="token string">"no"</span> <span class="token keyword keyword-else">else</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        peft_config<span class="token operator">=</span>get_peft_config<span class="token punctuation">(</span>model_args<span class="token punctuation">)</span><span class="token punctuation">,</span>
        callbacks<span class="token operator">=</span>get_callbacks<span class="token punctuation">(</span>training_args<span class="token punctuation">,</span> model_args<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    <span class="token comment">###############</span>
    <span class="token comment"># Training loop</span>
    <span class="token comment">###############</span>
    logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"*** Train ***"</span><span class="token punctuation">)</span>
    checkpoint <span class="token operator">=</span> <span class="token boolean">None</span>
    <span class="token keyword keyword-if">if</span> training_args<span class="token punctuation">.</span>resume_from_checkpoint <span class="token keyword keyword-is">is</span> <span class="token keyword keyword-not">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        checkpoint <span class="token operator">=</span> training_args<span class="token punctuation">.</span>resume_from_checkpoint
    <span class="token keyword keyword-elif">elif</span> last_checkpoint <span class="token keyword keyword-is">is</span> <span class="token keyword keyword-not">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        checkpoint <span class="token operator">=</span> last_checkpoint
    train_result <span class="token operator">=</span> trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span>resume_from_checkpoint<span class="token operator">=</span>checkpoint<span class="token punctuation">)</span>
    metrics <span class="token operator">=</span> train_result<span class="token punctuation">.</span>metrics
    metrics<span class="token punctuation">[</span><span class="token string">"train_samples"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">[</span>script_args<span class="token punctuation">.</span>dataset_train_split<span class="token punctuation">]</span><span class="token punctuation">)</span>
    trainer<span class="token punctuation">.</span>log_metrics<span class="token punctuation">(</span><span class="token string">"train"</span><span class="token punctuation">,</span> metrics<span class="token punctuation">)</span>
    trainer<span class="token punctuation">.</span>save_metrics<span class="token punctuation">(</span><span class="token string">"train"</span><span class="token punctuation">,</span> metrics<span class="token punctuation">)</span>
    trainer<span class="token punctuation">.</span>save_state<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">##################################</span>
    <span class="token comment"># Save model and create model card</span>
    <span class="token comment">##################################</span>
    logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"*** Save model ***"</span><span class="token punctuation">)</span>
    trainer<span class="token punctuation">.</span>save_model<span class="token punctuation">(</span>training_args<span class="token punctuation">.</span>output_dir<span class="token punctuation">)</span>
    logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Model saved to </span><span class="token interpolation"><span class="token punctuation">{</span>training_args<span class="token punctuation">.</span>output_dir<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre>
      </div>
      
      
    </body>
    
    
    
    
    
  </html>